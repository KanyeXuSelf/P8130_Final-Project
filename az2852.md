p8130_bm_final_proj
================
2024-11-25

``` r
library(tidyverse)
library(corrplot)
library(leaps)
library(glmnet)
library(faraway)
library(caret)
library(MASS) # boxcox
library(performance) # vif
```

``` r
df = read_csv("data/Project_1_data.csv")
```

    ## Rows: 948 Columns: 14
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (10): Gender, EthnicGroup, ParentEduc, LunchType, TestPrep, ParentMarita...
    ## dbl  (4): NrSiblings, MathScore, ReadingScore, WritingScore
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
score_df = df %>% 
  janitor::clean_names() %>% 
  drop_na() %>% # Drop rows with any missing values
  mutate(across(where(is.character), as.factor))
  

score_df
```

    ## # A tibble: 587 × 14
    ##    gender ethnic_group parent_educ    lunch_type test_prep parent_marital_status
    ##    <fct>  <fct>        <fct>          <fct>      <fct>     <fct>                
    ##  1 female group B      master's degr… standard   none      single               
    ##  2 male   group C      some college   standard   none      married              
    ##  3 female group B      associate's d… standard   none      married              
    ##  4 female group B      some college   standard   completed widowed              
    ##  5 male   group B      some college   free/redu… none      married              
    ##  6 male   group D      high school    free/redu… completed single               
    ##  7 male   group D      associate's d… standard   none      divorced             
    ##  8 female group B      high school    standard   none      married              
    ##  9 male   group A      some college   standard   completed single               
    ## 10 female group A      master's degr… standard   none      divorced             
    ## # ℹ 577 more rows
    ## # ℹ 8 more variables: practice_sport <fct>, is_first_child <fct>,
    ## #   nr_siblings <dbl>, transport_means <fct>, wkly_study_hours <fct>,
    ## #   math_score <dbl>, reading_score <dbl>, writing_score <dbl>

``` r
#create a df just for predicting math score
math_df = 
  score_df %>% 
  dplyr::select(-reading_score, -writing_score) %>% 
  dplyr::select(math_score, everything())
```

``` r
# Descriptive Statistics
summary(score_df)
```

    ##     gender     ethnic_group             parent_educ         lunch_type 
    ##  female:315   group A: 50   associate's degree:128   free/reduced:206  
    ##  male  :272   group B:123   bachelor's degree : 71   standard    :381  
    ##               group C:174   high school       :122                     
    ##               group D:155   master's degree   : 39                     
    ##               group E: 85   some college      :116                     
    ##                             some high school  :111                     
    ##      test_prep   parent_marital_status   practice_sport is_first_child
    ##  completed:208   divorced: 92          never    : 68    no :192       
    ##  none     :379   married :343          regularly:218    yes:395       
    ##                  single  :137          sometimes:301                  
    ##                  widowed : 15                                         
    ##                                                                       
    ##                                                                       
    ##   nr_siblings     transport_means wkly_study_hours   math_score    
    ##  Min.   :0.00   private   :229    < 5   :154       Min.   :  0.00  
    ##  1st Qu.:1.00   school_bus:358    > 10  :104       1st Qu.: 56.00  
    ##  Median :2.00                     10-May:329       Median : 67.00  
    ##  Mean   :2.14                                      Mean   : 66.68  
    ##  3rd Qu.:3.00                                      3rd Qu.: 78.00  
    ##  Max.   :7.00                                      Max.   :100.00  
    ##  reading_score    writing_score  
    ##  Min.   : 17.00   Min.   : 10.0  
    ##  1st Qu.: 60.00   1st Qu.: 58.0  
    ##  Median : 70.00   Median : 69.0  
    ##  Mean   : 69.85   Mean   : 68.9  
    ##  3rd Qu.: 81.00   3rd Qu.: 79.0  
    ##  Max.   :100.00   Max.   :100.0

``` r
# Check for missing values
colSums(is.na(score_df))
```

    ##                gender          ethnic_group           parent_educ 
    ##                     0                     0                     0 
    ##            lunch_type             test_prep parent_marital_status 
    ##                     0                     0                     0 
    ##        practice_sport        is_first_child           nr_siblings 
    ##                     0                     0                     0 
    ##       transport_means      wkly_study_hours            math_score 
    ##                     0                     0                     0 
    ##         reading_score         writing_score 
    ##                     0                     0

No missing values in the outcome variables. significant missing in
various predictor variables.

``` r
# Visualize distributions of outcome variables
ggplot(score_df, aes(x = math_score)) + 
  geom_histogram(binwidth = 5, fill = "blue", alpha = 0.7) + 
  labs(title = "Distribution of Math Scores", x = "Math Score", y = "Frequency") +
  theme_minimal()
```

![](az2852_files/figure-gfm/unnamed-chunk-3-1.png)<!-- -->

``` r
ggplot(score_df, aes(x = reading_score)) + 
  geom_histogram(binwidth = 5, fill = "green", alpha = 0.7) + 
  labs(title = "Distribution of Reading Scores", x = "Reading Score", y = "Frequency") +
  theme_minimal()
```

![](az2852_files/figure-gfm/unnamed-chunk-3-2.png)<!-- -->

``` r
ggplot(score_df, aes(x = writing_score)) + 
  geom_histogram(binwidth = 5, fill = "red", alpha = 0.7) + 
  labs(title = "Distribution of Writing Scores", x = "Writing Score", y = "Frequency") +
  theme_minimal()
```

![](az2852_files/figure-gfm/unnamed-chunk-3-3.png)<!-- -->

``` r
par(mfrow=c(1,3))
boxplot(score_df$math_score, main='math_score')
boxplot(score_df$reading_score, main='reading_score')
boxplot(score_df$writing_score, main='writing_score')
```

![](az2852_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

``` r
library(patchwork)
```

    ## 
    ## Attaching package: 'patchwork'

    ## The following object is masked from 'package:MASS':
    ## 
    ##     area

``` r
# Create individual bar plots for each categorical variable
plot_gender <- ggplot(score_df, aes(x = gender)) +
  geom_bar(fill = "skyblue") +
  labs(title = "Gender Distribution", x = "Gender", y = "Count") +
  theme_minimal()

plot_ethnic_group <- ggplot(score_df, aes(x = ethnic_group)) +
  geom_bar(fill = "lightgreen") +
  labs(title = "Ethnic Group Distribution", x = "Ethnic Group", y = "Count") +
  theme_minimal()

plot_parent_educ <- ggplot(score_df, aes(x = parent_educ)) +
  geom_bar(fill = "purple") +
  labs(title = "Parent Education Distribution", x = "Parent Education", y = "Count") +
  theme_minimal()

plot_lunch_type <- ggplot(score_df, aes(x = lunch_type)) +
  geom_bar(fill = "orange") +
  labs(title = "Lunch Type Distribution", x = "Lunch Type", y = "Count") +
  theme_minimal()

plot_test_prep <- ggplot(score_df, aes(x = test_prep)) +
  geom_bar(fill = "pink") +
  labs(title = "Test Prep Distribution", x = "Test Prep", y = "Count") +
  theme_minimal()

plot_practice_sport <- ggplot(score_df, aes(x = practice_sport)) +
  geom_bar(fill = "cyan") +
  labs(title = "Practice Sport Distribution", x = "Practice Sport", y = "Count") +
  theme_minimal()

# Example for other variables (add similar code for all remaining variables)
plot_is_first_child <- ggplot(score_df, aes(x = is_first_child)) +
  geom_bar(fill = "lightblue") +
  labs(title = "First Child Status Distribution", x = "Is First Child", y = "Count") +
  theme_minimal()

plot_nr_siblings <- ggplot(score_df, aes(x = factor(nr_siblings))) +
  geom_bar(fill = "red") +
  labs(title = "Number of Siblings Distribution", x = "Number of Siblings", y = "Count") +
  theme_minimal()

plot_transport_means <- ggplot(score_df, aes(x = transport_means)) +
  geom_bar(fill = "gold") +
  labs(title = "Transport Means Distribution", x = "Transport Means", y = "Count") +
  theme_minimal()

plot_wkly_study_hours <- ggplot(score_df, aes(x = wkly_study_hours)) +
  geom_bar(fill = "darkgreen") +
  labs(title = "Weekly Study Hours Distribution", x = "Weekly Study Hours", y = "Count") +
  theme_minimal()

# Adjusting plot layout with more vertical space
combined_plot <- (
  plot_gender + plot_ethnic_group + plot_parent_educ +
  plot_lunch_type + plot_test_prep + plot_practice_sport +
  plot_is_first_child + plot_nr_siblings +
  plot_transport_means + plot_wkly_study_hours
) + plot_layout(ncol = 2, heights = c(1, 1, 1, 1, 1)) # Adjust the number of rows to your needs

# Save as a larger plot with better dimensions
ggsave("combined_plot.png", combined_plot, width = 12, height = 18) # Adjust height/width

# Display the adjusted plot
print(combined_plot)
```

![](az2852_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

Use automatic procedures to find a ‘best subset’ of the full model for
predicting math scores.

``` r
# Full model
full_model <- lm(math_score ~ ., data = math_df)

summary(full_model)
```

    ## 
    ## Call:
    ## lm(formula = math_score ~ ., data = math_df)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -48.916  -9.265   0.725  10.104  33.013 
    ## 
    ## Coefficients:
    ##                              Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)                   49.0064     3.7750  12.982  < 2e-16 ***
    ## gendermale                     5.0855     1.1386   4.467 9.61e-06 ***
    ## ethnic_groupgroup B           -0.1788     2.3136  -0.077  0.93841    
    ## ethnic_groupgroup C           -0.2089     2.2149  -0.094  0.92489    
    ## ethnic_groupgroup D            3.6247     2.2286   1.626  0.10441    
    ## ethnic_groupgroup E           11.1752     2.4434   4.574 5.90e-06 ***
    ## parent_educbachelor's degree   1.7594     2.0219   0.870  0.38458    
    ## parent_educhigh school        -5.2293     1.7463  -2.994  0.00287 ** 
    ## parent_educmaster's degree     1.9038     2.5136   0.757  0.44912    
    ## parent_educsome college       -1.7126     1.7556  -0.976  0.32973    
    ## parent_educsome high school   -4.9058     1.7728  -2.767  0.00584 ** 
    ## lunch_typestandard            12.3539     1.1771  10.495  < 2e-16 ***
    ## test_prepnone                 -4.7717     1.2007  -3.974 7.99e-05 ***
    ## parent_marital_statusmarried   5.4805     1.6170   3.389  0.00075 ***
    ## parent_marital_statussingle    2.1682     1.8454   1.175  0.24053    
    ## parent_marital_statuswidowed   7.7944     3.8119   2.045  0.04134 *  
    ## practice_sportregularly        1.6701     1.9046   0.877  0.38092    
    ## practice_sportsometimes        1.5255     1.8439   0.827  0.40838    
    ## is_first_childyes              1.1303     1.2125   0.932  0.35162    
    ## nr_siblings                    0.7403     0.3844   1.926  0.05461 .  
    ## transport_meansschool_bus     -0.4319     1.1629  -0.371  0.71050    
    ## wkly_study_hours> 10           3.0384     1.7540   1.732  0.08378 .  
    ## wkly_study_hours10-May         3.5394     1.3429   2.636  0.00863 ** 
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 13.52 on 564 degrees of freedom
    ## Multiple R-squared:  0.3221, Adjusted R-squared:  0.2956 
    ## F-statistic: 12.18 on 22 and 564 DF,  p-value: < 2.2e-16

``` r
# Backward elimination
backward_model <- step(full_model, direction = "backward")
```

    ## Start:  AIC=3080.15
    ## math_score ~ gender + ethnic_group + parent_educ + lunch_type + 
    ##     test_prep + parent_marital_status + practice_sport + is_first_child + 
    ##     nr_siblings + transport_means + wkly_study_hours
    ## 
    ##                         Df Sum of Sq    RSS    AIC
    ## - practice_sport         2     149.5 103299 3077.0
    ## - transport_means        1      25.2 103175 3078.3
    ## - is_first_child         1     158.9 103308 3079.1
    ## <none>                               103149 3080.1
    ## - nr_siblings            1     678.4 103828 3082.0
    ## - wkly_study_hours       2    1299.9 104449 3083.5
    ## - parent_marital_status  3    2798.6 105948 3089.9
    ## - parent_educ            5    4174.0 107323 3093.4
    ## - test_prep              1    2888.2 106038 3094.4
    ## - gender                 1    3648.7 106798 3098.6
    ## - ethnic_group           4    8780.7 111930 3120.1
    ## - lunch_type             1   20145.7 123295 3182.9
    ## 
    ## Step:  AIC=3077
    ## math_score ~ gender + ethnic_group + parent_educ + lunch_type + 
    ##     test_prep + parent_marital_status + is_first_child + nr_siblings + 
    ##     transport_means + wkly_study_hours
    ## 
    ##                         Df Sum of Sq    RSS    AIC
    ## - transport_means        1      20.2 103319 3075.1
    ## - is_first_child         1     144.3 103443 3075.8
    ## <none>                               103299 3077.0
    ## - nr_siblings            1     676.7 103976 3078.8
    ## - wkly_study_hours       2    1325.3 104624 3080.5
    ## - parent_marital_status  3    2815.0 106114 3086.8
    ## - parent_educ            5    4108.3 107407 3089.9
    ## - test_prep              1    2955.2 106254 3091.6
    ## - gender                 1    3643.0 106942 3095.3
    ## - ethnic_group           4    8744.5 112043 3116.7
    ## - lunch_type             1   20057.7 123357 3179.2
    ## 
    ## Step:  AIC=3075.11
    ## math_score ~ gender + ethnic_group + parent_educ + lunch_type + 
    ##     test_prep + parent_marital_status + is_first_child + nr_siblings + 
    ##     wkly_study_hours
    ## 
    ##                         Df Sum of Sq    RSS    AIC
    ## - is_first_child         1     142.1 103461 3073.9
    ## <none>                               103319 3075.1
    ## - nr_siblings            1     675.5 103995 3076.9
    ## - wkly_study_hours       2    1319.0 104638 3078.6
    ## - parent_marital_status  3    2802.2 106121 3084.8
    ## - parent_educ            5    4088.2 107407 3087.9
    ## - test_prep              1    3021.0 106340 3090.0
    ## - gender                 1    3635.8 106955 3093.4
    ## - ethnic_group           4    8741.3 112060 3114.8
    ## - lunch_type             1   20047.0 123366 3177.2
    ## 
    ## Step:  AIC=3073.92
    ## math_score ~ gender + ethnic_group + parent_educ + lunch_type + 
    ##     test_prep + parent_marital_status + nr_siblings + wkly_study_hours
    ## 
    ##                         Df Sum of Sq    RSS    AIC
    ## <none>                               103461 3073.9
    ## - nr_siblings            1     629.8 104091 3075.5
    ## - wkly_study_hours       2    1344.8 104806 3077.5
    ## - parent_marital_status  3    2726.0 106187 3083.2
    ## - parent_educ            5    4053.0 107514 3086.5
    ## - test_prep              1    3115.5 106577 3089.3
    ## - gender                 1    3650.4 107112 3092.3
    ## - ethnic_group           4    8726.4 112188 3113.5
    ## - lunch_type             1   20082.2 123543 3176.1

``` r
summary(backward_model)
```

    ## 
    ## Call:
    ## lm(formula = math_score ~ gender + ethnic_group + parent_educ + 
    ##     lunch_type + test_prep + parent_marital_status + nr_siblings + 
    ##     wkly_study_hours, data = math_df)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -48.412  -8.860   0.405  10.319  33.266 
    ## 
    ## Coefficients:
    ##                              Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)                  50.96821    3.25206  15.673  < 2e-16 ***
    ## gendermale                    5.08556    1.13600   4.477 9.16e-06 ***
    ## ethnic_groupgroup B          -0.12625    2.30718  -0.055 0.956379    
    ## ethnic_groupgroup C          -0.06815    2.20498  -0.031 0.975356    
    ## ethnic_groupgroup D           3.71549    2.22091   1.673 0.094886 .  
    ## ethnic_groupgroup E          11.18161    2.43421   4.594 5.37e-06 ***
    ## parent_educbachelor's degree  1.71868    2.01735   0.852 0.394602    
    ## parent_educhigh school       -5.06167    1.73363  -2.920 0.003643 ** 
    ## parent_educmaster's degree    1.87883    2.49420   0.753 0.451595    
    ## parent_educsome college      -1.59208    1.74419  -0.913 0.361740    
    ## parent_educsome high school  -4.87887    1.76705  -2.761 0.005948 ** 
    ## lunch_typestandard           12.32626    1.17393  10.500  < 2e-16 ***
    ## test_prepnone                -4.92090    1.18986  -4.136 4.07e-05 ***
    ## parent_marital_statusmarried  5.41133    1.60455   3.372 0.000796 ***
    ## parent_marital_statussingle   2.13481    1.83057   1.166 0.244023    
    ## parent_marital_statuswidowed  7.48771    3.79448   1.973 0.048944 *  
    ## nr_siblings                   0.71090    0.38232   1.859 0.063482 .  
    ## wkly_study_hours> 10          3.04378    1.74927   1.740 0.082395 .  
    ## wkly_study_hours10-May        3.60274    1.33885   2.691 0.007335 ** 
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 13.5 on 568 degrees of freedom
    ## Multiple R-squared:   0.32,  Adjusted R-squared:  0.2985 
    ## F-statistic: 14.85 on 18 and 568 DF,  p-value: < 2.2e-16

``` r
# Null model (no predictors)
null_model <- lm(math_score ~ 1, data = math_df)

# Forward selection
forward_model <- step(null_model, direction = "forward", scope = formula(full_model))
```

    ## Start:  AIC=3264.33
    ## math_score ~ 1
    ## 
    ##                         Df Sum of Sq    RSS    AIC
    ## + lunch_type             1   22340.6 129816 3173.1
    ## + ethnic_group           4   11630.1 140526 3225.7
    ## + gender                 1    5114.8 147042 3246.3
    ## + test_prep              1    4114.3 148042 3250.2
    ## + parent_educ            5    4397.1 147759 3257.1
    ## + wkly_study_hours       2    2365.3 149791 3259.1
    ## + parent_marital_status  3    2625.8 149531 3260.1
    ## + nr_siblings            1     615.0 151541 3264.0
    ## <none>                               152157 3264.3
    ## + is_first_child         1     132.5 152024 3265.8
    ## + transport_means        1       0.3 152156 3266.3
    ## + practice_sport         2      17.8 152139 3268.3
    ## 
    ## Step:  AIC=3173.12
    ## math_score ~ lunch_type
    ## 
    ##                         Df Sum of Sq    RSS    AIC
    ## + ethnic_group           4   10097.8 119718 3133.6
    ## + test_prep              1    4711.5 125104 3153.4
    ## + gender                 1    4049.1 125767 3156.5
    ## + parent_educ            5    4657.6 125158 3161.7
    ## + parent_marital_status  3    2481.0 127335 3167.8
    ## + wkly_study_hours       2    2008.6 127807 3168.0
    ## + nr_siblings            1     601.2 129215 3172.4
    ## <none>                               129816 3173.1
    ## + is_first_child         1      93.5 129722 3174.7
    ## + transport_means        1       1.5 129814 3175.1
    ## + practice_sport         2      76.4 129739 3176.8
    ## 
    ## Step:  AIC=3133.59
    ## math_score ~ lunch_type + ethnic_group
    ## 
    ##                         Df Sum of Sq    RSS    AIC
    ## + test_prep              1    4077.4 115641 3115.2
    ## + gender                 1    3574.9 116143 3117.8
    ## + parent_marital_status  3    3208.1 116510 3123.7
    ## + parent_educ            5    3901.2 115817 3124.1
    ## + wkly_study_hours       2    1623.3 118095 3129.6
    ## + nr_siblings            1     669.1 119049 3132.3
    ## <none>                               119718 3133.6
    ## + is_first_child         1      82.1 119636 3135.2
    ## + transport_means        1       1.2 119717 3135.6
    ## + practice_sport         2     178.0 119540 3136.7
    ## 
    ## Step:  AIC=3115.25
    ## math_score ~ lunch_type + ethnic_group + test_prep
    ## 
    ##                         Df Sum of Sq    RSS    AIC
    ## + gender                 1    3258.7 112382 3100.5
    ## + parent_marital_status  3    3343.5 112297 3104.0
    ## + parent_educ            5    3694.7 111946 3106.2
    ## + wkly_study_hours       2    1226.5 114414 3113.0
    ## + nr_siblings            1     527.9 115113 3114.6
    ## <none>                               115641 3115.2
    ## + is_first_child         1      34.0 115607 3117.1
    ## + transport_means        1      12.8 115628 3117.2
    ## + practice_sport         2     113.8 115527 3118.7
    ## 
    ## Step:  AIC=3100.47
    ## math_score ~ lunch_type + ethnic_group + test_prep + gender
    ## 
    ##                         Df Sum of Sq    RSS    AIC
    ## + parent_educ            5    4081.3 108301 3088.8
    ## + parent_marital_status  3    3157.1 109225 3089.7
    ## + wkly_study_hours       2    1243.9 111138 3097.9
    ## + nr_siblings            1     631.9 111750 3099.2
    ## <none>                               112382 3100.5
    ## + is_first_child         1      24.9 112357 3102.3
    ## + transport_means        1       7.4 112375 3102.4
    ## + practice_sport         2     118.4 112264 3103.8
    ## 
    ## Step:  AIC=3088.76
    ## math_score ~ lunch_type + ethnic_group + test_prep + gender + 
    ##     parent_educ
    ## 
    ##                         Df Sum of Sq    RSS    AIC
    ## + parent_marital_status  3   2912.61 105388 3078.8
    ## + wkly_study_hours       2   1385.30 106915 3085.2
    ## + nr_siblings            1    681.65 107619 3087.1
    ## <none>                               108301 3088.8
    ## + is_first_child         1     46.96 108254 3090.5
    ## + transport_means        1      2.22 108298 3090.7
    ## + practice_sport         2    172.15 108129 3091.8
    ## 
    ## Step:  AIC=3078.75
    ## math_score ~ lunch_type + ethnic_group + test_prep + gender + 
    ##     parent_educ + parent_marital_status
    ## 
    ##                    Df Sum of Sq    RSS    AIC
    ## + wkly_study_hours  2   1297.10 104091 3075.5
    ## + nr_siblings       1    582.04 104806 3077.5
    ## <none>                          105388 3078.8
    ## + is_first_child    1    118.24 105270 3080.1
    ## + transport_means   1     11.07 105377 3080.7
    ## + practice_sport    2    153.50 105235 3081.9
    ## 
    ## Step:  AIC=3075.48
    ## math_score ~ lunch_type + ethnic_group + test_prep + gender + 
    ##     parent_educ + parent_marital_status + wkly_study_hours
    ## 
    ##                   Df Sum of Sq    RSS    AIC
    ## + nr_siblings      1    629.79 103461 3073.9
    ## <none>                         104091 3075.5
    ## + is_first_child   1     96.35 103995 3076.9
    ## + transport_means  1     17.33 104074 3077.4
    ## + practice_sport   2    131.10 103960 3078.7
    ## 
    ## Step:  AIC=3073.92
    ## math_score ~ lunch_type + ethnic_group + test_prep + gender + 
    ##     parent_educ + parent_marital_status + wkly_study_hours + 
    ##     nr_siblings
    ## 
    ##                   Df Sum of Sq    RSS    AIC
    ## <none>                         103461 3073.9
    ## + is_first_child   1   142.106 103319 3075.1
    ## + transport_means  1    18.041 103443 3075.8
    ## + practice_sport   2   130.088 103331 3077.2

``` r
# Summary of the final model
summary(forward_model)
```

    ## 
    ## Call:
    ## lm(formula = math_score ~ lunch_type + ethnic_group + test_prep + 
    ##     gender + parent_educ + parent_marital_status + wkly_study_hours + 
    ##     nr_siblings, data = math_df)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -48.412  -8.860   0.405  10.319  33.266 
    ## 
    ## Coefficients:
    ##                              Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)                  50.96821    3.25206  15.673  < 2e-16 ***
    ## lunch_typestandard           12.32626    1.17393  10.500  < 2e-16 ***
    ## ethnic_groupgroup B          -0.12625    2.30718  -0.055 0.956379    
    ## ethnic_groupgroup C          -0.06815    2.20498  -0.031 0.975356    
    ## ethnic_groupgroup D           3.71549    2.22091   1.673 0.094886 .  
    ## ethnic_groupgroup E          11.18161    2.43421   4.594 5.37e-06 ***
    ## test_prepnone                -4.92090    1.18986  -4.136 4.07e-05 ***
    ## gendermale                    5.08556    1.13600   4.477 9.16e-06 ***
    ## parent_educbachelor's degree  1.71868    2.01735   0.852 0.394602    
    ## parent_educhigh school       -5.06167    1.73363  -2.920 0.003643 ** 
    ## parent_educmaster's degree    1.87883    2.49420   0.753 0.451595    
    ## parent_educsome college      -1.59208    1.74419  -0.913 0.361740    
    ## parent_educsome high school  -4.87887    1.76705  -2.761 0.005948 ** 
    ## parent_marital_statusmarried  5.41133    1.60455   3.372 0.000796 ***
    ## parent_marital_statussingle   2.13481    1.83057   1.166 0.244023    
    ## parent_marital_statuswidowed  7.48771    3.79448   1.973 0.048944 *  
    ## wkly_study_hours> 10          3.04378    1.74927   1.740 0.082395 .  
    ## wkly_study_hours10-May        3.60274    1.33885   2.691 0.007335 ** 
    ## nr_siblings                   0.71090    0.38232   1.859 0.063482 .  
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 13.5 on 568 degrees of freedom
    ## Multiple R-squared:   0.32,  Adjusted R-squared:  0.2985 
    ## F-statistic: 14.85 on 18 and 568 DF,  p-value: < 2.2e-16

``` r
# Stepwise regression
stepwise_model <- step(full_model, direction = "both")
```

    ## Start:  AIC=3080.15
    ## math_score ~ gender + ethnic_group + parent_educ + lunch_type + 
    ##     test_prep + parent_marital_status + practice_sport + is_first_child + 
    ##     nr_siblings + transport_means + wkly_study_hours
    ## 
    ##                         Df Sum of Sq    RSS    AIC
    ## - practice_sport         2     149.5 103299 3077.0
    ## - transport_means        1      25.2 103175 3078.3
    ## - is_first_child         1     158.9 103308 3079.1
    ## <none>                               103149 3080.1
    ## - nr_siblings            1     678.4 103828 3082.0
    ## - wkly_study_hours       2    1299.9 104449 3083.5
    ## - parent_marital_status  3    2798.6 105948 3089.9
    ## - parent_educ            5    4174.0 107323 3093.4
    ## - test_prep              1    2888.2 106038 3094.4
    ## - gender                 1    3648.7 106798 3098.6
    ## - ethnic_group           4    8780.7 111930 3120.1
    ## - lunch_type             1   20145.7 123295 3182.9
    ## 
    ## Step:  AIC=3077
    ## math_score ~ gender + ethnic_group + parent_educ + lunch_type + 
    ##     test_prep + parent_marital_status + is_first_child + nr_siblings + 
    ##     transport_means + wkly_study_hours
    ## 
    ##                         Df Sum of Sq    RSS    AIC
    ## - transport_means        1      20.2 103319 3075.1
    ## - is_first_child         1     144.3 103443 3075.8
    ## <none>                               103299 3077.0
    ## - nr_siblings            1     676.7 103976 3078.8
    ## + practice_sport         2     149.5 103149 3080.1
    ## - wkly_study_hours       2    1325.3 104624 3080.5
    ## - parent_marital_status  3    2815.0 106114 3086.8
    ## - parent_educ            5    4108.3 107407 3089.9
    ## - test_prep              1    2955.2 106254 3091.6
    ## - gender                 1    3643.0 106942 3095.3
    ## - ethnic_group           4    8744.5 112043 3116.7
    ## - lunch_type             1   20057.7 123357 3179.2
    ## 
    ## Step:  AIC=3075.11
    ## math_score ~ gender + ethnic_group + parent_educ + lunch_type + 
    ##     test_prep + parent_marital_status + is_first_child + nr_siblings + 
    ##     wkly_study_hours
    ## 
    ##                         Df Sum of Sq    RSS    AIC
    ## - is_first_child         1     142.1 103461 3073.9
    ## <none>                               103319 3075.1
    ## - nr_siblings            1     675.5 103995 3076.9
    ## + transport_means        1      20.2 103299 3077.0
    ## + practice_sport         2     144.4 103175 3078.3
    ## - wkly_study_hours       2    1319.0 104638 3078.6
    ## - parent_marital_status  3    2802.2 106121 3084.8
    ## - parent_educ            5    4088.2 107407 3087.9
    ## - test_prep              1    3021.0 106340 3090.0
    ## - gender                 1    3635.8 106955 3093.4
    ## - ethnic_group           4    8741.3 112060 3114.8
    ## - lunch_type             1   20047.0 123366 3177.2
    ## 
    ## Step:  AIC=3073.92
    ## math_score ~ gender + ethnic_group + parent_educ + lunch_type + 
    ##     test_prep + parent_marital_status + nr_siblings + wkly_study_hours
    ## 
    ##                         Df Sum of Sq    RSS    AIC
    ## <none>                               103461 3073.9
    ## + is_first_child         1     142.1 103319 3075.1
    ## - nr_siblings            1     629.8 104091 3075.5
    ## + transport_means        1      18.0 103443 3075.8
    ## + practice_sport         2     130.1 103331 3077.2
    ## - wkly_study_hours       2    1344.8 104806 3077.5
    ## - parent_marital_status  3    2726.0 106187 3083.2
    ## - parent_educ            5    4053.0 107514 3086.5
    ## - test_prep              1    3115.5 106577 3089.3
    ## - gender                 1    3650.4 107112 3092.3
    ## - ethnic_group           4    8726.4 112188 3113.5
    ## - lunch_type             1   20082.2 123543 3176.1

``` r
# Summary of the final model
summary(stepwise_model)
```

    ## 
    ## Call:
    ## lm(formula = math_score ~ gender + ethnic_group + parent_educ + 
    ##     lunch_type + test_prep + parent_marital_status + nr_siblings + 
    ##     wkly_study_hours, data = math_df)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -48.412  -8.860   0.405  10.319  33.266 
    ## 
    ## Coefficients:
    ##                              Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)                  50.96821    3.25206  15.673  < 2e-16 ***
    ## gendermale                    5.08556    1.13600   4.477 9.16e-06 ***
    ## ethnic_groupgroup B          -0.12625    2.30718  -0.055 0.956379    
    ## ethnic_groupgroup C          -0.06815    2.20498  -0.031 0.975356    
    ## ethnic_groupgroup D           3.71549    2.22091   1.673 0.094886 .  
    ## ethnic_groupgroup E          11.18161    2.43421   4.594 5.37e-06 ***
    ## parent_educbachelor's degree  1.71868    2.01735   0.852 0.394602    
    ## parent_educhigh school       -5.06167    1.73363  -2.920 0.003643 ** 
    ## parent_educmaster's degree    1.87883    2.49420   0.753 0.451595    
    ## parent_educsome college      -1.59208    1.74419  -0.913 0.361740    
    ## parent_educsome high school  -4.87887    1.76705  -2.761 0.005948 ** 
    ## lunch_typestandard           12.32626    1.17393  10.500  < 2e-16 ***
    ## test_prepnone                -4.92090    1.18986  -4.136 4.07e-05 ***
    ## parent_marital_statusmarried  5.41133    1.60455   3.372 0.000796 ***
    ## parent_marital_statussingle   2.13481    1.83057   1.166 0.244023    
    ## parent_marital_statuswidowed  7.48771    3.79448   1.973 0.048944 *  
    ## nr_siblings                   0.71090    0.38232   1.859 0.063482 .  
    ## wkly_study_hours> 10          3.04378    1.74927   1.740 0.082395 .  
    ## wkly_study_hours10-May        3.60274    1.33885   2.691 0.007335 ** 
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 13.5 on 568 degrees of freedom
    ## Multiple R-squared:   0.32,  Adjusted R-squared:  0.2985 
    ## F-statistic: 14.85 on 18 and 568 DF,  p-value: < 2.2e-16

- Do the procedures generate the same model?

### backward elimination model

significant predictors (7), same as stepwise model: `gender`
`ethnic_group` `parent_educ` `lunch_type` `test_prep`
`parent_marital_status` `wkly_study_hours`

### forward selection model

significant predictors (5): `gender` not significant `ethnic_group`
`parent_educ` `lunch_type` `test_prep` not significant
`parent_marital_status` `wkly_study_hours`

### step-wise regression model

significant predictors (7): `gender` `ethnic_group` `parent_educ`
`lunch_type` `test_prep` `parent_marital_status` `wkly_study_hours`

Since multi-colinearity can make a predictor appear less significant, we
should check for it.

``` r
vif(lm(math_score ~ ., data = math_df))
```

    ##                   gendermale          ethnic_groupgroup B 
    ##                     1.034618                     2.845495 
    ##          ethnic_groupgroup C          ethnic_groupgroup D 
    ##                     3.283702                     3.097841 
    ##          ethnic_groupgroup E parent_educbachelor's degree 
    ##                     2.372927                     1.395067 
    ##       parent_educhigh school   parent_educmaster's degree 
    ##                     1.611557                     1.257784 
    ##      parent_educsome college  parent_educsome high school 
    ##                     1.568503                     1.546840 
    ##           lunch_typestandard                test_prepnone 
    ##                     1.012939                     1.058701 
    ## parent_marital_statusmarried  parent_marital_statussingle 
    ##                     2.038332                     1.955689 
    ## parent_marital_statuswidowed      practice_sportregularly 
    ##                     1.161314                     2.718020 
    ##      practice_sportsometimes            is_first_childyes 
    ##                     2.726220                     1.038500 
    ##                  nr_siblings    transport_meansschool_bus 
    ##                     1.039492                     1.032714 
    ##         wkly_study_hours> 10       wkly_study_hours10-May 
    ##                     1.439583                     1.425941

None of the VIFs are larger than 5, so multi-colinearity is likely not a
concern.

Use criterion-based procedures to guide your selection of the ‘best
subset’. Summarize your results (tabular or graphical).

``` r
# convert data to numeric
math_df_numeric = math_df %>% 
  mutate(across(where(is.factor), ~ as.numeric(.)))
```

``` r
mat = as.matrix(math_df_numeric)
# Printing the 2 best models of each size, using the Cp criterion:
leaps(x = mat[,2:12], y = mat[,1], nbest = 2, method = "Cp")
```

    ## $which
    ##        1     2     3     4     5     6     7     8     9     A     B
    ## 1  FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 1  FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 2  FALSE  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 2  FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 3  FALSE  TRUE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 3   TRUE  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 4   TRUE  TRUE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 4  FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 5   TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 5   TRUE  TRUE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE
    ## 6   TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE
    ## 6   TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE
    ## 7   TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE FALSE  TRUE
    ## 7   TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE  TRUE
    ## 8   TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE FALSE  TRUE
    ## 8   TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE
    ## 9   TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE
    ## 9   TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE
    ## 10  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE
    ## 10  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE
    ## 11  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
    ## 
    ## $label
    ##  [1] "(Intercept)" "1"           "2"           "3"           "4"          
    ##  [6] "5"           "6"           "7"           "8"           "9"          
    ## [11] "A"           "B"          
    ## 
    ## $size
    ##  [1]  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10 11 11 12
    ## 
    ## $Cp
    ##  [1]  87.135817 162.178565  53.953897  64.813885  32.725714  35.213894
    ##  [7]  15.744985  26.745239  10.247064  11.925933   6.395909   9.357764
    ## [13]   5.149679   7.492994   6.374130   6.890386   8.031665   8.350999
    ## [19]  10.010907  10.019172  12.000000

``` r
# Printing the 2 best models of each size, using the adjusted R^2 criterion:
leaps(x = mat[,2:12], y = mat[,1], nbest = 2, method = "adjr2")
```

    ## $which
    ##        1     2     3     4     5     6     7     8     9     A     B
    ## 1  FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 1  FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 2  FALSE  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 2  FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 3  FALSE  TRUE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 3   TRUE  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 4   TRUE  TRUE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 4  FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 5   TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
    ## 5   TRUE  TRUE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE
    ## 6   TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE
    ## 6   TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE
    ## 7   TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE FALSE  TRUE
    ## 7   TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE  TRUE
    ## 8   TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE FALSE  TRUE
    ## 8   TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE
    ## 9   TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE
    ## 9   TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE
    ## 10  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE
    ## 10  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE
    ## 11  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
    ## 
    ## $label
    ##  [1] "(Intercept)" "1"           "2"           "3"           "4"          
    ##  [6] "5"           "6"           "7"           "8"           "9"          
    ## [11] "A"           "B"          
    ## 
    ## $size
    ##  [1]  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10 11 11 12
    ## 
    ## $adjr2
    ##  [1] 0.1453682 0.0496653 0.1888495 0.1749759 0.2171829 0.2139989 0.2401690
    ##  [8] 0.2260679 0.2484892 0.2463334 0.2547199 0.2509100 0.2576156 0.2545961
    ## [15] 0.2573322 0.2566658 0.2564879 0.2560750 0.2552240 0.2552133 0.2539428

``` r
# Function regsubsets() performs a subset selection by identifying the "best" model that contains
# a certain number of predictors. By default "best" is chosen using SSE/RSS (smaller is better)
b = regsubsets(math_score ~ ., data = math_df_numeric)
rs = summary(b)

# plot of Cp and Adj-R2 as functions of parameters
par(mfrow=c(1,2))

plot(2:9, rs$cp, xlab="No of parameters", ylab="Cp Statistic")
abline(0,1)

plot(2:9, rs$adjr2, xlab="No of parameters", ylab="Adj R2")
```

![](az2852_files/figure-gfm/unnamed-chunk-12-1.png)<!-- --> Cp is close
to p at 7 predictors; Adjusted R square increases rapidly from 2-5
predictors and peaks at 8 predictors. Overall it seems like 7 or 8 would
be a good choice.

Use the LASSO method to perform variable selection. Make sure you choose
the “best lambda” to use and show how you determined this.

``` r
# Separate the response variable (life_exp) and predictors
y <- math_df_numeric$math_score
X <- as.matrix(math_df_numeric[, -1])  # Exclude the response variable

# Fit LASSO model with cross-validation
lasso_cv <- cv.glmnet(X, y, alpha = 1)  # alpha = 1 for LASSO (L2 regularization)

# Plot the cross-validation results
plot(lasso_cv)
```

![](az2852_files/figure-gfm/unnamed-chunk-13-1.png)<!-- -->

``` r
# Best lambda (lambda.min is the one that minimizes cross-validation error)
best_lambda <- lasso_cv$lambda.min
best_lambda
```

    ## [1] 0.344908

``` r
# Coefficients at the best lambda
lasso_coefs <- coef(lasso_cv, s = "lambda.min")
print(lasso_coefs)
```

    ## 12 x 1 sparse Matrix of class "dgCMatrix"
    ##                               s1
    ## (Intercept)           38.0323559
    ## gender                 4.4629185
    ## ethnic_group           2.6059491
    ## parent_educ           -0.6620777
    ## lunch_type            11.7191873
    ## test_prep             -4.6326261
    ## parent_marital_status  0.2288852
    ## practice_sport         .        
    ## is_first_child         .        
    ## nr_siblings            0.4643881
    ## transport_means        .        
    ## wkly_study_hours       1.2873132

The LASSO model narrows down to 9 predictors: `gender` `ethnic_group`
`parent_educ` `lunch_type` `test_prep` `parent_marital_status`
`wkly_study_hours` `is_first_child` `nr_siblings`

# evaluating candidate models

## MLR assumptions

### 7-predictor model

- how are the models in terms of assumptions?

``` r
model_1 = lm(math_score ~ gender + ethnic_group + parent_educ + lunch_type
+ test_prep + parent_marital_status + wkly_study_hours, data = math_df)

plot(model_1)
```

![](az2852_files/figure-gfm/unnamed-chunk-14-1.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-14-2.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-14-3.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-14-4.png)<!-- -->
QQ plot doesn’t seem so normal, some deviation at large values. Let’s
try a transformation.

``` r
math_df$math_score <- math_df$math_score + 1

boxcox(model_1, lambda = seq(-3, 3, by = 0.25))
```

![](az2852_files/figure-gfm/unnamed-chunk-15-1.png)<!-- --> looks like a
power of 1.5 is recommended.

``` r
math_df_tr = math_df %>% 
  mutate(sqrt_math_score = sqrt(math_score),
         log_math_score = log(math_score),
         ahalf_math_score = (math_score)^1.5)

model_1.5 = lm(sqrt_math_score ~ gender + ethnic_group + parent_educ + lunch_type
+ test_prep + parent_marital_status + wkly_study_hours, data = math_df_tr)

model_1.6 = lm(log_math_score ~ gender + ethnic_group + parent_educ + lunch_type
+ test_prep + parent_marital_status + wkly_study_hours, data = math_df_tr)

model_1.7 = lm(ahalf_math_score ~ gender + ethnic_group + parent_educ + lunch_type
+ test_prep + parent_marital_status + wkly_study_hours, data = math_df_tr)

plot(model_1)
```

![](az2852_files/figure-gfm/unnamed-chunk-16-1.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-16-2.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-16-3.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-16-4.png)<!-- -->

``` r
plot(model_1.5)
```

![](az2852_files/figure-gfm/unnamed-chunk-16-5.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-16-6.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-16-7.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-16-8.png)<!-- -->

``` r
plot(model_1.6)
```

![](az2852_files/figure-gfm/unnamed-chunk-16-9.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-16-10.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-16-11.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-16-12.png)<!-- -->

``` r
plot(model_1.7)
```

![](az2852_files/figure-gfm/unnamed-chunk-16-13.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-16-14.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-16-15.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-16-16.png)<!-- -->
The QQ plot did not get better with transformation.

### 5-predictor model

``` r
model_2 = lm(math_score ~ ethnic_group + parent_educ + lunch_type + parent_marital_status + wkly_study_hours, data = math_df)

plot(model_2)
```

![](az2852_files/figure-gfm/unnamed-chunk-17-1.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-17-2.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-17-3.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-17-4.png)<!-- -->
looks good (?) \### 9-predictor model

``` r
model_3 = lm(math_score ~ gender + ethnic_group + parent_educ + lunch_type
+ test_prep + parent_marital_status + wkly_study_hours + is_first_child + nr_siblings,
data = math_df)

plot(model_3)
```

![](az2852_files/figure-gfm/unnamed-chunk-18-1.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-18-2.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-18-3.png)<!-- -->![](az2852_files/figure-gfm/unnamed-chunk-18-4.png)<!-- -->
same issue with QQ plot

## Predictive power

### 7-predictor model

RMSE 13.70

``` r
set.seed(1)
# Use 10-fold validation and create the training sets
train = trainControl(method = "cv", number = 10)

# Fit the 4-variables model
model_caret = train(math_score ~ gender + ethnic_group + parent_educ + lunch_type
+ test_prep + parent_marital_status + wkly_study_hours, data = math_df,
                   trControl = train,
                   method = 'lm',
                   na.action = na.pass)

model_caret$finalModel
```

    ## 
    ## Call:
    ## lm(formula = .outcome ~ ., data = dat)
    ## 
    ## Coefficients:
    ##                    (Intercept)                      gendermale  
    ##                        53.7237                          4.9788  
    ##          `ethnic_groupgroup B`           `ethnic_groupgroup C`  
    ##                        -0.3532                         -0.1087  
    ##          `ethnic_groupgroup D`           `ethnic_groupgroup E`  
    ##                         3.5102                         11.0406  
    ## `parent_educbachelor's degree`        `parent_educhigh school`  
    ##                         1.5860                         -4.9685  
    ##   `parent_educmaster's degree`       `parent_educsome college`  
    ##                         1.6565                         -1.6345  
    ##  `parent_educsome high school`              lunch_typestandard  
    ##                        -5.0577                         12.3459  
    ##                  test_prepnone    parent_marital_statusmarried  
    ##                        -5.0316                          5.5078  
    ##    parent_marital_statussingle    parent_marital_statuswidowed  
    ##                         2.2403                          7.8685  
    ##         `wkly_study_hours> 10`        `wkly_study_hours10-May`  
    ##                         3.2082                          3.4990

``` r
print(model_caret)
```

    ## Linear Regression 
    ## 
    ## 587 samples
    ##   7 predictor
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (10 fold) 
    ## Summary of sample sizes: 529, 527, 529, 528, 529, 528, ... 
    ## Resampling results:
    ## 
    ##   RMSE      Rsquared   MAE     
    ##   13.71335  0.2777857  11.13378
    ## 
    ## Tuning parameter 'intercept' was held constant at a value of TRUE

### 5-predictor model

RMSE 14.13

``` r
train = trainControl(method = "cv", number = 10)

# Fit the 4-variables model
model_caret = train(math_score ~ ethnic_group + parent_educ + lunch_type + parent_marital_status + wkly_study_hours, data = math_df,
                   trControl = train,
                   method = 'lm',
                   na.action = na.pass)

model_caret$finalModel
```

    ## 
    ## Call:
    ## lm(formula = .outcome ~ ., data = dat)
    ## 
    ## Coefficients:
    ##                    (Intercept)           `ethnic_groupgroup B`  
    ##                        53.1586                         -1.0695  
    ##          `ethnic_groupgroup C`           `ethnic_groupgroup D`  
    ##                        -0.7503                          2.8056  
    ##          `ethnic_groupgroup E`  `parent_educbachelor's degree`  
    ##                        11.0971                          1.5017  
    ##       `parent_educhigh school`    `parent_educmaster's degree`  
    ##                        -5.1646                          0.9057  
    ##      `parent_educsome college`   `parent_educsome high school`  
    ##                        -2.3393                         -4.9307  
    ##             lunch_typestandard    parent_marital_statusmarried  
    ##                        12.4578                          5.4861  
    ##    parent_marital_statussingle    parent_marital_statuswidowed  
    ##                         2.1932                          8.2634  
    ##         `wkly_study_hours> 10`        `wkly_study_hours10-May`  
    ##                         4.1708                          3.7276

``` r
print(model_caret)
```

    ## Linear Regression 
    ## 
    ## 587 samples
    ##   5 predictor
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (10 fold) 
    ## Summary of sample sizes: 528, 527, 529, 528, 529, 529, ... 
    ## Resampling results:
    ## 
    ##   RMSE      Rsquared   MAE     
    ##   14.09591  0.2400184  11.49503
    ## 
    ## Tuning parameter 'intercept' was held constant at a value of TRUE

### 9-predictor model

RMSE 13.72

``` r
train = trainControl(method = "cv", number = 10)

# Fit the 9-variables model
model_caret = train(math_score ~ gender + ethnic_group + parent_educ + lunch_type
+ test_prep + parent_marital_status + wkly_study_hours + is_first_child + nr_siblings,
data = math_df,
                   trControl = train,
                   method = 'lm',
                   na.action = na.pass)

model_caret$finalModel
```

    ## 
    ## Call:
    ## lm(formula = .outcome ~ ., data = dat)
    ## 
    ## Coefficients:
    ##                    (Intercept)                      gendermale  
    ##                        51.1532                          5.0756  
    ##          `ethnic_groupgroup B`           `ethnic_groupgroup C`  
    ##                        -0.1980                         -0.1356  
    ##          `ethnic_groupgroup D`           `ethnic_groupgroup E`  
    ##                         3.7048                         11.1211  
    ## `parent_educbachelor's degree`        `parent_educhigh school`  
    ##                         1.7228                         -5.1485  
    ##   `parent_educmaster's degree`       `parent_educsome college`  
    ##                         1.7710                         -1.6432  
    ##  `parent_educsome high school`              lunch_typestandard  
    ##                        -4.8906                         12.3161  
    ##                  test_prepnone    parent_marital_statusmarried  
    ##                        -4.8552                          5.5403  
    ##    parent_marital_statussingle    parent_marital_statuswidowed  
    ##                         2.2769                          7.6811  
    ##         `wkly_study_hours> 10`        `wkly_study_hours10-May`  
    ##                         3.0292                          3.5676  
    ##              is_first_childyes                     nr_siblings  
    ##                         1.0650                          0.7388

``` r
print(model_caret)
```

    ## Linear Regression 
    ## 
    ## 587 samples
    ##   9 predictor
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (10 fold) 
    ## Summary of sample sizes: 528, 529, 530, 527, 527, 528, ... 
    ## Resampling results:
    ## 
    ##   RMSE      Rsquared   MAE     
    ##   13.67099  0.2894601  11.21909
    ## 
    ## Tuning parameter 'intercept' was held constant at a value of TRUE

Overall, the 7 predictors is the best (?)
