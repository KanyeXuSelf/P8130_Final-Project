---
title: "Writing Scores Analysis"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(dplyr)
library(MASS)
library(car)
library(glmnet)
library(caret)
```


## Import and Clean the Data
```{r}
writing = read.csv(file = "./data/Project_1_data.csv") |> 
  janitor::clean_names() |> 
  mutate(across(where(is.character), ~na_if(.x, "")))
  
writing = writing |> 
  filter(!is.na(writing_score)) |> 
  drop_na()

head(writing)
```


## Descriptive Statistics
```{r}
summary(writing$writing_score)

var(writing$writing_score)
sd(writing$writing_score)
```


## Percentiles
```{r}
percentiles = quantile(writing$writing_score, probs = seq(0.1, 1, by = 0.1))

print(percentiles)
```


## Visualizations
```{r}
ggplot(writing, aes(x = writing_score)) +
  geom_histogram(binwidth = 5, fill = "blue", color = "black", alpha = 0.7) +
  labs(
    title = "Distribution of Writing Scores",
    x = "Score",
    y = "Frequency")
```

```{r}
ggplot(writing, aes(x = writing_score)) +
  geom_density(fill = "purple", alpha = 0.5) +
  labs(
    title = "Density Plot of Writing Scores",
    x = "Writing Score",
    y = "Density")
```

```{r}
ggplot(writing, aes(x = gender, y = writing_score)) +
  geom_boxplot(fill = "lightblue") +
  labs(
    title = "Writing Scores by Gender",
    x = "Gender",
    y = "Writing Score")
```


```{r}
ggplot(writing, aes(x = ethnic_group, y = writing_score)) +
  geom_boxplot(fill = "lightgreen") +
  labs(
    title = "Writing Scores by Ethnic Group",
    x = "Ethnic Group",
    y = "Writing Score")
```

```{r}
ggplot(writing, aes(x = parent_educ, y = writing_score)) +
  geom_boxplot(fill = "lightpink") +
  labs(
    title = "Writing Scores by Parent Education",
    x = "Parent Education",
    y = "Writing Score")
```

```{r}
ggplot(writing, aes(x = lunch_type, y = writing_score)) +
  geom_boxplot(fill = "yellow") +
  labs(
    title = "Writing Scores by Lunch Type",
    x = "Lunch Type",
    y = "Writing Score")
```

```{r}
ggplot(writing, aes(x = test_prep, y = writing_score)) +
  geom_boxplot(fill = "orange") +
  labs(
    title = "Writing Scores by Test Prep",
    x = "Test Prep",
    y = "Writing Score")
```

```{r}
ggplot(writing, aes(x = parent_marital_status, y = writing_score)) +
  geom_boxplot(fill = "navyblue") +
  labs(
    title = "Writing Scores by Parent Marital Status",
    x = "Parent Marital Status",
    y = "Writing Score")
```

```{r}
ggplot(writing, aes(x = practice_sport, y = writing_score)) +
  geom_boxplot(fill = "thistle") +
  labs(
    title = "Writing Scores by Practice Sport",
    x = "Practice Sport",
    y = "Writing Score")
```

```{r}
ggplot(writing, aes(x = is_first_child, y = writing_score)) +
  geom_boxplot(fill = "sienna") +
  labs(
    title = "Writing Scores by First Child",
    x = "First Child",
    y = "Writing Score")
```

```{r}
ggplot(writing, aes(x = nr_siblings, y = writing_score)) +
  geom_boxplot(fill = "salmon") +
  labs(
    title = "Writing Scores by Number of Siblings",
    x = "Number of Siblings",
    y = "Writing Score")
```

```{r}
ggplot(writing, aes(x = transport_means, y = writing_score)) +
  geom_boxplot(fill = "royalblue") +
  labs(
    title = "Writing Scores by Transportation Means",
    x = "Transportation Means",
    y = "Writing Score")
```

```{r}
ggplot(writing, aes(x = wkly_study_hours, y = writing_score)) +
  geom_boxplot(fill = "orchid") +
  labs(
    title = "Writing Scores by Weekly Study Hours",
    x = "Weekly Study Hours",
    y = "Writing Score")
```

## Statistical Testing
We used procedures to investigate significant predictors associated with writing scores. 

### Linear Regression 
```{r}
lm_model = lm(writing_score ~ gender + ethnic_group + parent_educ + lunch_type + test_prep + parent_marital_status + practice_sport + is_first_child + nr_siblings + transport_means + wkly_study_hours, data = writing)

summary(lm_model)
```
We used procedures to investigate significant predictors associated with writing scores. Backward, forward, and stepwise as well as criterion-based and LASSO regression was used to model the predictors against writing scores and identify significant predictors. The significant predictors extracted in the model are gender, ethnic group, parent education, lunch type, test preparation, parent marital status and weekly study hours. 

We first used linear regression to model the relationship between writing scores and predictors to quantify the strength and direction of the relationship. The significant predictors with p-values less than 0.05 which indicates a statistically significant relationship are gender (Male), ethnic group (D, E), parent education, (Some High School, High School, Master's Degree), lunch type (Standard), test prep (None), parent marital status (Married), and weekly study hours (10-May). 

The residual standard error of 12.65 indicates the model's predicitions are off by about 12.65 points.
The multiple R-squared of 0.3634 means about 36.34% of the variation in the writing scores can be explained by the predictors.
The f-statistic of 14.63 and a p-value of less than 0.05 indicates a highly significant model. 

### Correlation Matrix
```{r}
writing = writing |> 
  mutate(across(c(gender, ethnic_group, parent_educ, lunch_type, test_prep, parent_marital_status, practice_sport, is_first_child, nr_siblings, transport_means, wkly_study_hours), as.factor))

writing_encoded = writing |> 
  mutate(across(where(is.factor), as.numeric))

cor_writing = writing_encoded |> 
  select_if(is.numeric)

cor_matrix = cor(cor_writing, use = "complete.obs", method = "pearson")

print(cor_matrix)
```

```{r}
cor_table = knitr::kable(cor_matrix, format = "markdown")

print(cor_table)
```
Pearson's correlation is used to measure the linear relationship between variables and improve interpretibility. According to the correlation matrix, there is strong positive correlation between writing and reading scores as well as writing and math scores, 0.96 and 0.81 respectively. This suggests that students who do well in writing, tend to do well in reading and math, and more likely perform better in reading compared to math.

Additionally, the predictors indicate correlation with writing scores. 
Gender has a negative correlation of -0.28, indicating that males tend to have lower writing scores compared to females. Lunch type shows a moderate positive correlation of 0.27 meaning students on a standard lunch plan tend to perform better. Furthermore, test prep has a negative correlation with writing scores of -0.26 which means students who did not complete test prep tend to have lower scores. These predictors showed significant correlation with writing scores, aligning with regression analysis. 

### Backward Elimination Method
```{r}
full_model = lm(writing_score ~ gender + ethnic_group + parent_educ + lunch_type + test_prep + parent_marital_status + practice_sport + is_first_child + nr_siblings + transport_means + wkly_study_hours, data = writing)

backward_model = step(full_model, direction = "backward")

summary(backward_model)
```


### Forward Selection
```{r}
empty_model = lm(writing_score ~ 1, data = writing)

forward_model = step(empty_model, 
                     scope = list(lower = empty_model, 
                                  upper = ~ gender + ethnic_group + parent_educ + lunch_type + test_prep + parent_marital_status + practice_sport + is_first_child + nr_siblings + transport_means + wkly_study_hours), direction = "forward")

summary(forward_model)
```

### Stepwise Method (stepAIC)
```{r}
null_model = lm(writing_score ~ 1, data = writing)

stepwise_model = stepAIC(full_model, direction = "both", trace = TRUE)

summary(stepwise_model)
```
Backward, forward, and stepwise are used for model selection and used to identfy important predictors by simplifying the model and reducing overfitting. The three models confirm the significant predictors indentified in the linear regression model.

### Checking for Multicollinearity
```{r}
vif_values = vif(lm_model)
print(vif_values)

high_vif = vif_values[vif_values > 5]
print(high_vif)
```
We checked for multicollinearity by calculating the Variance Inflation Factor (VIF) for each predictor. Since none of the values exceed 5, there are no collinearity issues that could inflate standard errors and lead to unreliable coefficient estimates. 

### Criterion-Based Procedures

Applying AIC-Based Stepwise Selection
```{r}
aic_stepwise = stepAIC(full_model, scope = list(lower = null_model, upper = full_model), direction = "both", trace = TRUE)

summary(aic_stepwise)
```

Applying BIC-Based Stepwise Selection
```{r}
n = nrow(writing)
bic_stepwise = stepAIC(full_model, scope = list(lower = null_model, upper = full_model), direction = "both", trace = TRUE, k = log(n))

summary(bic_stepwise)
```
Criterion-based selection is used to identify the model that offers the best trade-off of fit and simplicity to avoid overfitting. AIC measure the goodness of fit and BIC is similar but includes a heavier penatly for adding additional predictors.

### LASSO
```{r}
X = model.matrix(writing_score ~ gender + ethnic_group + parent_educ + lunch_type + test_prep + parent_marital_status + practice_sport + is_first_child + nr_siblings + transport_means + wkly_study_hours, data = writing)[, -1]

Y = writing$writing_score
```

```{r}
set.seed(123)
lasso_cv = cv.glmnet(X, Y, alpha = 1)
```

```{r}
best_lambda = lasso_cv$lambda.min
lasso_model = glmnet(X, Y, alpha = 1, lambda = best_lambda)
```

```{r}
lasso_coefficients = coef(lasso_model)
print(lasso_coefficients)
```
The LASSO regression performs both variable selection and regularization. According to the model, the variables with meaningful contribution are gender and lunch type. Gender has a coefficient of -8.64 indicating that male students have a writing score 8.64 points lower than female students on average. Lunch type has a coefficient of 8.57 indicating that students with a standard lunch type score 8.57 points higher on average than those with free/reduced lunch. Additionally, ethnic group and practice sport have coefficients of 0 indicating no significant impact on writing scores.


### Predictive Power through cross-validation
```{r}
set.seed(123)
train_control = trainControl(method = "cv", number = 10)

lasso_caret = train(
  writing_score ~ gender + ethnic_group + parent_educ + lunch_type + test_prep + parent_marital_status + practice_sport + is_first_child + nr_siblings + transport_means + wkly_study_hours, data = writing, method = "glmnet", trControl = train_control, tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 1, length = 100)))

print(lasso_caret)
```

```{r}
predictions = predict(lasso_caret$finalModel, newx = X, s = lasso_caret$bestTune$lambda)

mse = mean((predictions - Y)^2)
r2 = 1 - (sum((Y - predictions)^2) / sum((Y - mean(Y))^2))
mae = mean(abs(predictions - Y))

print(paste("Test RMSE:", sqrt(mse)))
print(paste("Test R-Squared:", r2))
print(paste("Test MAE:", mae))
```

```{r}
dev.new()
plot(residuals(lasso_caret), main = "Residuals Plot", ylab = "Residuals")
abline(h = 0, col = "red")
```

### Interaction Effect
```{r}
interaction_model = lm(writing_score ~ gender * practice_sport + parent_educ * test_prep, data = writing)

summary(interaction_model)
```

ANOVA
```{r}
base_model = lm(writing_score ~ gender + practice_sport, data = writing)

anova(base_model, interaction_model)
```

Procedures as mentioned help to simplify the model and improve prediction accuracy. Interaction effects were also explored and metrics were computed to asses the model's predictive power. From the model, males consistently score lower than females, regardless of sport participation, completing test prep has a positive impact on writing scores, and lower parent educaation are associated with significantly lower scores, however, higher parent education does not schow significant benefit.

It is important to note that the R-sqaured suggets that there are important predictors of writing scores not included and that there are no significant interaction effects.